# ShieldVLM: Cross-Modal Content Safety Assessment Model

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

<a name="english"></a>

## English

ShieldVLM is an advanced Vision-Language Model (VLM) specifically designed to evaluate the safety risks within combined text and image content (cross-modal content). It possesses a deep understanding of the correlation between text and images, enabling it to identify a wide range of potential risks.

### âœ¨ Features

ShieldVLM can identify the following seven major categories of safety risks:

1.  **Offensiveness**: Threat, insult, scorn, profanity, sarcasm, impoliteness, etc.
2.  **Discrimination & Stereotyping**: Social bias across various topics such as race, gender, religion, age, etc.
3.  **Physical Harm**: Actions or expressions that may influence human physical health.
4.  **Illegal Activities**: Behaviors that could cause negative societal repercussions.
5.  **Violation of Morality**: Immoral activities that do not necessarily violate the law.
6.  **Privacy & Property Damage**: Issues related to privacy and property loss.
7.  **Misinformation**: Misleading or false information.

The model supports three core assessment tasks:
* **Statement Safety Assessment**: Directly assesses whether a given text-image pair contains safety risks.
* **Prompt Safety Assessment**: Evaluates whether a question combined with an image could lead to an unsafe or harmful response.
* **Dialogue Safety Assessment**: Assesses the safety of a response within a multimodal dialogue context.

### Models and Datasets

* **Model Hub**: [thu-coai/ShieldVLM-7B-qwen](https://huggingface.co/thu-coai/ShieldVLM-7B-qwen)
* **Dataset Hub**: [thu-coai/ShieldVLM](https://huggingface.co/datasets/thu-coai/ShieldVLM)

### âš™ï¸ Setup and Installation

1.  Clone this repository.
2.  Install the required dependencies. It is recommended to use a virtual environment.

    ```bash
    pip install -r requirements.txt
    ```
    Key dependencies include `transformers`, `torch`, `peft`, and `trl`.

### ğŸš€ Quick Start

#### Inference

You can use the `infer_shieldvlm.sh` script to quickly perform safety assessments on your data.

1.  **Prepare Input Data**:
    Prepare your data according to the format in the `examples/` directory (e.g., `examples/statement/example_input.json`). Each entry should contain an `id`, `risk_type`, `image` (path to the image), and `text`.

2.  **Run the Inference Script**:
    Modify the paths in `infer_shieldvlm.sh` or execute `infer.py` directly from the command line.

    ```bash
    # Example: Run statement safety assessment
    MODEL_PATH="thu-coai/ShieldVLM-7B-qwen" # Or your local model path

    CUDA_VISIBLE_DEVICES=0 python infer.py \
        --category "statement" \
        --model_path ${MODEL_PATH} \
        --input_path ./examples/statement/example_input.json \
        --output_path ./examples/statement/example_output.json
    ```
    * `--category`: The type of task. Options include `statement`, `prompt`, `dialog`.
    * `--model_path`: Path to your model checkpoint on Hugging Face or a local directory.
    * `--input_path`: Path to the input `json` file.
    * `--output_path`: Path to save the output `json` file with assessment results.

#### Training

ShieldVLM was trained via full supervised fine-tuning based on the `Qwen2.5-VL-7B-Instruct` model, using the **LLaMA Factory** framework.

1.  **Prepare Datasets**:
    The training set needs to be prepared according to the requirements of the **LLaMA Factory** framework. You can use the `train` folder within our [Dataset Hub](https://huggingface.co/datasets/thu-coai/ShieldVLM) as the source for the training set.

2.  **Configure Training**:
    Modify the configuration file in `train_code/` (e.g., `train_shieldvlm.yaml`) to set your model, dataset paths, and training hyperparameters.

3.  **Start Training with LLaMA Factory**:
    Execute the following script to begin training.

    ```bash
    bash train_code/run.sh
    ```
   

---

<a name="ä¸­æ–‡"></a>

## ä¸­æ–‡

ShieldVLM æ˜¯ä¸€ä¸ªå…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ (Vision-Language Model, VLM)ï¼Œä¸“ä¸ºè¯„ä¼°æ–‡æœ¬ä¸å›¾åƒç»„åˆï¼ˆè·¨æ¨¡æ€å†…å®¹ï¼‰ä¸­çš„å®‰å…¨é£é™©è€Œè®¾è®¡ã€‚å®ƒèƒ½å¤Ÿæ·±åº¦ç†è§£å›¾æ–‡ä¹‹é—´çš„å…³è”ï¼Œå¹¶è¯†åˆ«å¤šç§æ½œåœ¨çš„é£é™©ç±»å‹ã€‚

### âœ¨ åŠŸèƒ½ç‰¹æ€§

ShieldVLM èƒ½å¤Ÿè¯†åˆ«ä»¥ä¸‹ä¸ƒä¸ªä¸»è¦ç±»åˆ«çš„å®‰å…¨é£é™©ï¼š

1.  **å†’çŠ¯æ€§ (Offensiveness)**: æ¶‰åŠå¨èƒã€ä¾®è¾±ã€å˜²è®½ã€äºµæ¸ã€è®½åˆºç­‰ä¸ç¤¼è²Œå†…å®¹ã€‚
2.  **æ­§è§†ä¸åˆ»æ¿å°è±¡ (Discrimination & Stereotyping)**: æ¶‰åŠç§æ—ã€æ€§åˆ«ã€å®—æ•™ã€å¹´é¾„ç­‰æ–¹é¢çš„ç¤¾ä¼šåè§ã€‚
3.  **äººèº«ä¼¤å®³ (Physical Harm)**: å…³æ³¨å¯èƒ½å½±å“äººç±»èº«ä½“å¥åº·çš„è¡Œä¸ºæˆ–è¡¨è¿°ã€‚
4.  **è¿æ³•æ´»åŠ¨ (Illegal Activities)**: å…³æ³¨å¯èƒ½å¯¼è‡´è´Ÿé¢ç¤¾ä¼šå½±å“çš„éæ³•è¡Œä¸ºã€‚
5.  **è¿èƒŒé“å¾· (Violation of Morality)**: é™¤æ˜ç¡®è¿æ³•å¤–çš„å…¶ä»–ä¸é“å¾·æ´»åŠ¨ã€‚
6.  **éšç§ä¸è´¢äº§æŸå®³ (Privacy & Property Damage)**: å…³æ³¨ä¸éšç§å’Œè´¢äº§æŸå¤±ç›¸å…³çš„é—®é¢˜ã€‚
7.  **è¯¯å¯¼æ€§ä¿¡æ¯ (Misinformation)**: å…³æ³¨è¯¯å¯¼æ€§æˆ–è™šå‡ä¿¡æ¯ã€‚

æ¨¡å‹æ”¯æŒä¸‰ç§æ ¸å¿ƒçš„è¯„ä¼°ä»»åŠ¡ï¼š
* **é™ˆè¿°å®‰å…¨è¯„ä¼° (Statement Safety)**: ç›´æ¥è¯„ä¼°ç»™å®šçš„å›¾æ–‡å†…å®¹æ˜¯å¦å­˜åœ¨å®‰å…¨é£é™©ã€‚
* **é—®é¢˜å®‰å…¨è¯„ä¼° (Prompt Safety)**: è¯„ä¼°ä¸€ä¸ªç»“åˆäº†å›¾åƒçš„é—®é¢˜æ˜¯å¦ä¼šå¼•å¯¼å‡ºä¸å®‰å…¨æˆ–æœ‰å®³çš„å›ç­”ã€‚
* **å¯¹è¯å®‰å…¨è¯„ä¼° (Dialogue Safety)**: åœ¨å›¾æ–‡å¯¹è¯ä¸­ï¼Œè¯„ä¼°å›ç­”çš„å®‰å…¨æ€§ã€‚

### æ¨¡å‹ä¸æ•°æ®é›†

* **æ¨¡å‹ä»“åº“**: [thu-coai/ShieldVLM-7B-qwen](https://huggingface.co/thu-coai/ShieldVLM-7B-qwen)
* **æ•°æ®é›†ä»“åº“**: [thu-coai/ShieldVLM](https://huggingface.co/datasets/thu-coai/ShieldVLM)

### âš™ï¸ ç¯å¢ƒå®‰è£…

1.  å…‹éš†æœ¬ä»“åº“ã€‚
2.  å®‰è£…æ‰€éœ€çš„ä¾èµ–åŒ…ã€‚å»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒã€‚

    ```bash
    pip install -r requirements.txt
    ```
    ä¸»è¦ä¾èµ–åŒ…æ‹¬ `transformers`, `torch`, `peft`, å’Œ `trl`ã€‚

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### æ¨ç† (Inference)

æ‚¨å¯ä»¥ä½¿ç”¨ `infer_shieldvlm.sh` è„šæœ¬å¿«é€Ÿå¯¹æ‚¨çš„æ•°æ®è¿›è¡Œå®‰å…¨è¯„ä¼°ã€‚

1.  **å‡†å¤‡è¾“å…¥æ•°æ®**:
    å‚ç…§ `examples/` ç›®å½•ä¸‹çš„æ–‡ä»¶æ ¼å¼ (ä¾‹å¦‚ `examples/statement/example_input.json`) å‡†å¤‡æ‚¨çš„æ•°æ®ã€‚ æ¯ä¸ªæ¡ç›®åº”åŒ…å« `id`, `risk_type`, `image` (å›¾ç‰‡è·¯å¾„) å’Œ `text`ã€‚

2.  **è¿è¡Œæ¨ç†è„šæœ¬**:
    ä¿®æ”¹ `infer_shieldvlm.sh` è„šæœ¬ä¸­çš„è·¯å¾„ï¼Œæˆ–ç›´æ¥é€šè¿‡å‘½ä»¤è¡Œæ‰§è¡Œ `infer.py`ã€‚

    ```bash
    # ç¤ºä¾‹: è¿è¡Œé™ˆè¿°å®‰å…¨è¯„ä¼°
    MODEL_PATH="thu-coai/ShieldVLM-7B-qwen" # æˆ–æ‚¨çš„æœ¬åœ°æ¨¡å‹è·¯å¾„

    CUDA_VISIBLE_DEVICES=0 python infer.py \
        --category "statement" \
        --model_path ${MODEL_PATH} \
        --input_path ./examples/statement/example_input.json \
        --output_path ./examples/statement/example_output.json
    ```
    * `--category`: ä»»åŠ¡ç±»å‹ï¼Œå¯é€‰å€¼ä¸º `statement`, `prompt`, `dialog`ã€‚
    * `--model_path`: æ‚¨åœ¨ Hugging Face ä¸Šçš„æ¨¡å‹ä»“åº“åæˆ–æœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚
    * `--input_path`: è¾“å…¥çš„ `json` æ–‡ä»¶è·¯å¾„ã€‚
    * `--output_path`: ä¿å­˜è¯„ä¼°ç»“æœçš„ `json` æ–‡ä»¶è·¯å¾„ã€‚

#### è®­ç»ƒ (Training)

ShieldVLM åŸºäº `Qwen2.5-VL-7B-Instruct` æ¨¡å‹ï¼Œé€šè¿‡å¼ºå¤§çš„ **LLaMA Factory** æ¡†æ¶è¿›è¡Œå…¨é‡ç›‘ç£å¼å¾®è°ƒ (Supervised Fine-tuning) è®­ç»ƒè€Œæ¥ã€‚

1.  **å‡†å¤‡æ•°æ®é›†**:
    è®­ç»ƒé›†éœ€è¦æ ¹æ® **LLaMA Factory** æ¡†æ¶çš„è¦æ±‚è¿›è¡Œç¼–è¾‘ã€‚æ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬ [æ•°æ®é›†ä»“åº“](https://huggingface.co/datasets/thu-coai/ShieldVLM) ä¸­çš„ `train` æ–‡ä»¶å¤¹ä½œä¸ºè®­ç»ƒé›†æ¥æºã€‚

2.  **é…ç½®è®­ç»ƒå‚æ•°**:
    åœ¨ `train_code/` ç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶ (ä¾‹å¦‚ `train_shieldvlm.yaml`) ä¸­ä¿®æ”¹æ‚¨çš„æ¨¡å‹ã€æ•°æ®é›†è·¯å¾„åŠè®­ç»ƒè¶…å‚æ•°ã€‚

3.  **ä½¿ç”¨ LLaMA Factory å¯åŠ¨è®­ç»ƒ**:
    æ‰§è¡Œä»¥ä¸‹è„šæœ¬æ¥å¼€å§‹è®­ç»ƒã€‚

    ```bash
    bash train_code/run.sh
    ```